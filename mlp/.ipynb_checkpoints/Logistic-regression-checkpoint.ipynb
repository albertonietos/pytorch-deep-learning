{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression\n",
    "In this notebook, a simple logistic regression model is implemented in Pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import seaborn as sns; sns.set()\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select device which you are going to use for training\n",
    "device = torch.device(\"cuda:0\")\n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "The data set that is used is the [**Wine Quality Data Set**](https://archive.ics.uci.edu/ml/datasets/Wine+Quality)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.039</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>57.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.041</td>\n",
       "      <td>30.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.022</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.020</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "4893            6.2              0.21         0.29             1.6      0.039   \n",
       "4894            6.6              0.32         0.36             8.0      0.047   \n",
       "4895            6.5              0.24         0.19             1.2      0.041   \n",
       "4896            5.5              0.29         0.30             1.1      0.022   \n",
       "4897            6.0              0.21         0.38             0.8      0.020   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "4893                 24.0                  92.0  0.99114  3.27       0.50   \n",
       "4894                 57.0                 168.0  0.99490  3.15       0.46   \n",
       "4895                 30.0                 111.0  0.99254  2.99       0.46   \n",
       "4896                 20.0                 110.0  0.98869  3.34       0.38   \n",
       "4897                 22.0                  98.0  0.98941  3.26       0.32   \n",
       "\n",
       "      alcohol  quality  \n",
       "4893     11.2        6  \n",
       "4894      9.6        5  \n",
       "4895      9.4        6  \n",
       "4896     12.8        7  \n",
       "4897     11.8        6  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_wine = pd.read_csv(\"../data/winequality-red.csv\", delimiter=';')\n",
    "white_wine = pd.read_csv(\"../data/winequality-white.csv\", delimiter=';')\n",
    "data = pd.concat([red_wine, white_wine])\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attribute `quality` is our dependent variable that we are trying to predict, so it will be dropped from the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6497, 11]), torch.Size([6497]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = torch.Tensor(data.loc[:,data.columns!='quality'].values)\n",
    "labels = torch.Tensor(data.quality.values)\n",
    "features.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 4., 5., 6., 7., 8., 9.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We transform the labels so that this becomes a binary classification problem:\n",
    "- `y=0` if the wine quality is deemed less than 7,\n",
    "- `y=1` if the wine quality is deemed greater or equal than 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = (labels >= 7).float().view(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train and test splits\n",
    "20% of the data will be used for testing, the rest will be used for training.\n",
    "The split will be performed by randomly subsampling from the the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_feats, test_feats, \n",
    " train_labels, test_labels) = train_test_split(features, labels, test_size=.2,\n",
    "                                           random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features : torch.Size([5197, 11]), torch.Size([1300, 11])\n",
      "Labels : torch.Size([5197, 1]), torch.Size([1300, 1])\n"
     ]
    }
   ],
   "source": [
    "# Check shapes\n",
    "print(f\"Features : {train_feats.shape}, {test_feats.shape}\")\n",
    "print(f\"Labels : {train_labels.shape}, {test_labels.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize the features\n",
    "In order to facilitate the optimization problem, we will standardize the features, that is:\n",
    "- **zero mean**: the mean is subtracted from the data point along each feature,\n",
    "- **unit variance**: each feature is divided by its standard deviation.\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "It is important to notice that this preprocessing step should be performed using the statistics obtained in the training set only.\n",
    "Otherwise, we would suffer <b>data leakage</b>: information from the test set would be used, which would not be possible in the real scenario.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(train_feats)\n",
    "train_feats = scaler.transform(train_feats)\n",
    "test_feats = scaler.transform(test_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.645565121600527e-16"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check scaling\n",
    "np.mean(train_feats[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5197, 11]), torch.Size([1300, 11]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform features back to torch tensors\n",
    "train_feats = torch.Tensor(train_feats)\n",
    "test_feats = torch.Tensor(test_feats)\n",
    "train_feats.shape, test_feats.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build logistic regression classifier\n",
    "Here, we build the logistic regression model as a PyTorch module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, n_inputs=11):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.fc1 = nn.Linear(n_inputs, 1)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          x of shape (n_samples, n_inputs): Model inputs.\n",
    "        \n",
    "        Returns:\n",
    "          y of shape (n_samples, 1): Model outputs.\n",
    "        \"\"\"\n",
    "        y = torch.sigmoid(self.fc1(x))\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the accuracy of the model on the given dataset\n",
    "def compute_accuracy(model, inputs, targets):\n",
    "    with torch.no_grad():\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = (model.forward(inputs) > 0.5).float()\n",
    "        accuracy = (outputs == targets).sum().float() / targets.numel()\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(\n",
       "  (fc1): Linear(in_features=11, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model\n",
    "model = LogisticRegression()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = []\n",
    "train_feats, train_labels = train_feats.to(device), train_labels.to(device)\n",
    "for iter in range(8000):\n",
    "    model.zero_grad()\n",
    "    out = model(train_feats)\n",
    "    loss = F.binary_cross_entropy(out, train_labels)\n",
    "    loss.backward()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    train_acc_iter = compute_accuracy(model, train_feats, train_labels)\n",
    "    train_acc.append(train_acc_iter)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Evolution of training accuracy')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_acc)\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Evolution of training accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model converged to a training accuracy of 0.8158553242683411.\n",
      "The model achieved a test accuracy of 0.823846161365509\n"
     ]
    }
   ],
   "source": [
    "test_acc = compute_accuracy(model, test_feats, test_labels)\n",
    "print(f\"The model converged to a training accuracy of {train_acc[-1]}.\")\n",
    "print(f\"The model achieved a test accuracy of {test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclussion**. Althought the model achieved 0.816 training accuracy, it still achieved 0.823 test accuracy. The fact that the test accuracy is above training could mean that the model is simple enough to learn a good mapping from the features to the labels. It could also be that the validation set (which was subsampled randomly) is easier than the training data.\n",
    "In order to have a more reliable estimation of the out-of-sample performance, it would be good to perform this process more than once: **K-fold cross-validation**.\n",
    "Furthermore, the model already converges after 2000 iterations, so there is no need to train any longer than that."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
